---
{"dg-publish":true,"permalink":"/notion/theoretical-knowledge/computer-science/artificial-intelligence/deep-learning/"}
---

### 1. 神经网络 (Neural Network)

![Image/Deep Learning/1.png](/img/user/Image/Deep%20Learning/1.png)
从左往右依次是：**输入层 (Input Layer)**   **隐藏层 (Hidden Layer)**   **输出层 (Output Layer)**

1. **输入层 (Input Layer / 输入层)**
    
    - **作用**: 接收原始数据或特征。网络从这一层获取信息。
        
    - **神经元数量**: 通常等于输入数据的特征数量。例如，如果你的输入是一张28x28像素的灰度图片，展平后输入层就有784个神经元，每个神经元对应一个像素值。
        
    - **计算**: 输入层通常不做任何计算，它只是将输入值传递给下一层（隐藏层）。有时可能会进行一些预处理，如归一化。
        

---

1. **隐藏层 (Hidden Layer / 隐藏层)**
    
    - **作用**: 这是网络的核心，负责从输入数据中学习和提取复杂的特征和模式。隐藏层通过对输入数据进行非线性变换，使得网络能够学习非线性关系。
        
    - **神经元数量**: 隐藏层中神经元的数量是一个超参数，需要根据具体问题和数据进行调整和优化。可以有一个或多个隐藏层（如果多于一个隐藏层，就称为深度神经网络）。在一个“三层神经网络”的经典定义中，通常指一个隐藏层。
        
    - **计算**:
        
        - 每个隐藏层的神经元都会接收来自前一层（输入层）所有神经元的加权输入。
            
        - 计算加权和：
        - $$z = (\omega_1*x_1 + \omega_2*x_2 + ... + \omega_n*x_n) + b$$
        - 其中 $x$ 是输入，$\omega$ 是权重，$b$ 是偏置。
         写成矩阵形式则是：
         $$\begin{pmatrix} 
         a_0^{(j+1)} \\
         a_1^{(j+1)} \\
         \vdots \\
         a_n^{(j+1)}
         \end{pmatrix}
         =
         \begin{pmatrix} 
         \omega_{0,0} & \omega_{0,1} & \cdots & \omega_{0,n} \\
         \omega_{1,0} & \omega_{1,1} & \cdots & \omega_{1,n} \\
         \omega_{2,0} & \omega_{2,1} & \cdots & \omega_{2,n} \\
         \vdots & \vdots & \ddots & \vdots \\
         \omega_{k,0} & \omega_{k,1} & \cdots & \omega_{k,n} \\
         \end{pmatrix}
         \begin{pmatrix} 
         a_0^{(j)} \\
         a_1^{(j)} \\
         \vdots \\
         a_n^{(j)}
         \end{pmatrix}+\begin{pmatrix} 
         b_0 \\
         b_1 \\
         \vdots \\
         b_n
         \end{pmatrix}
         $$
         即
         $$z^{(j+1)}=Wz^{(j)}+b$$
		 **训练的进行就是要改变这些参数以达到最优解**
            
        - 将加权和通过一个**激活函数 (Activation Function)**（如 Sigmoid, ReLU, Tanh 等）进行非线性转换：$a = \text{activation-function}(z)$。这个激活后的值 a 会作为下一层（输出层）的输入。
         
         **Sigmoid**: $\dfrac{1}{1+e^{-x}}$
         **ReLU**: $\max{(0,x)}$
         **Tanh**: $\tanh x$
			
    - **重要性**: 隐藏层的存在使得神经网络能够学习比线性模型复杂得多的函数。
        

---

1. **输出层 (Output Layer / 输出层)**
    
    - **作用**: 产生网络的最终输出，即预测结果或决策。
        
    - **神经元数量**: 输出层神经元的数量取决于具体的任务类型：
        
        - **二分类问题** (e.g., 是/否, 猫/狗): 通常有1个神经元，使用 Sigmoid 激活函数输出一个0到1之间的概率值。
            
        - **多分类问题** (e.g., 数字0-9识别): 通常有N个神经元，N等于类别数量，使用 Softmax 激活函数输出每个类别的概率分布。
            
        - **回归问题** (e.g., 预测房价): 通常有1个神经元（如果要预测多个值，则有对应数量的神经元），通常不使用激活函数或使用线性激活函数。
            
    - **计算**: 与隐藏层类似，输出层的神经元接收来自前一层（隐藏层）的加权输入，计算加权和，并通过适合任务的激活函数得到最终输出。

**前向传播 Forward Propagation:**

数据从输入层开始，依次通过隐藏层，最后到达输出层，得到最终的预测结果。这个过程称为前向传播。

### 2. 代价函数 (Cost Function / 损失函数 Loss Function)

**引言 (Introduction):**
在定义了神经网络的结构之后（即模型如何从输入 $x$ 得到预测输出 $\hat{y}$），我们需要一种方法来**衡量模型的预测结果有多好或多差**。这个衡量标准就是**代价函数 (Cost Function)**，有时也称为**损失函数 (Loss Function)** 或目标函数 (Objective Function)。代价函数量化了模型预测值与真实目标值之间的差异。**我们的目标是通过调整神经网络的参数（权重 $w$ 和偏置 $b$）来最小化这个代价函数。**

---

1.  **作用 (Purpose):**
    *   **评估模型性能 (Evaluate Model Performance)**: 提供一个量化的指标来判断模型在训练数据上的表现。代价越小，通常意味着模型预测越接近真实值。
    *   **指导参数优化 (Guide Parameter Optimization)**: 代价函数是梯度下降等优化算法的目标。优化算法通过计算代价函数关于模型参数的梯度，来朝着减小代价的方向更新参数。

---

2.  **定义与表示 (Definition and Notation):**
    *   代价函数通常表示为 $J(\theta)$ 或 $L(\theta)$，其中 $\theta$ 代表模型的所有可学习参数（例如，神经网络中的所有权重 $w$ 和偏置 $b$）。
    *   对于单个训练样本 $(x^{(i)}, y^{(i)})$，我们通常先定义一个**损失 (loss)**，它衡量了在该样本上的预测误差，例如 $L(\hat{y}^{(i)}, y^{(i)})$。
    *   **代价函数 (Cost Function)** 通常是整个训练集上所有样本损失的平均值（或总和）。如果训练集有 $m$ 个样本，则：
        $$ J(\theta) = \frac{1}{m} \sum_{i=1}^{m} L(\hat{y}^{(i)}(\theta; x^{(i)}), y^{(i)}) $$
        其中 $\hat{y}^{(i)}(\theta; x^{(i)})$ 表示模型使用参数 $\theta$ 对输入 $x^{(i)}$ 做出的预测。

---

3.  **常见的代价函数 (Common Cost Functions):**

    *   **针对回归问题 (For Regression Problems):**
        *   **均方误差 (Mean Squared Error, MSE)**:
            *   **公式**: $J(\theta) = \frac{1}{m} \sum_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)})^2$
            *   (有时为了求导方便会写成 $J(\theta) = \frac{1}{2m} \sum_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)})^2$)
            *   **特点**: 对误差进行平方，使得较大的误差受到更大的惩罚。是回归任务中最常用的损失函数之一。
        *   **平均绝对误差 (Mean Absolute Error, MAE)**:
            *   **公式**: $J(\theta) = \frac{1}{m} \sum_{i=1}^{m} |\hat{y}^{(i)} - y^{(i)}|$
            *   **特点**: 对异常值不如 MSE 敏感。

    *   **针对二分类问题 (For Binary Classification Problems):**
        *   (其中 $y^{(i)} \in \{0, 1\}$，$\hat{y}^{(i)}$ 是模型预测样本为类别 1 的概率，通常是 Sigmoid 函数的输出)
        *   **二元交叉熵损失 (Binary Cross-Entropy Loss / Log Loss)**:
            *   **单个样本的损失**: $L(\hat{y}^{(i)}, y^{(i)}) = - [y^{(i)} \log(\hat{y}^{(i)}) + (1 - y^{(i)}) \log(1 - \hat{y}^{(i)})]$
            *   **整个数据集的代价**: $J(\theta) = - \frac{1}{m} \sum_{i=1}^{m} [y^{(i)} \log(\hat{y}^{(i)}) + (1 - y^{(i)}) \log(1 - \hat{y}^{(i)})]$
            *   **特点**: 当模型预测正确且置信度高时，损失小；当预测错误或置信度低时，损失大。与 Sigmoid 激活函数配合良好。

    *   **针对多分类问题 (For Multi-class Classification Problems):**
        *   (其中类别有 $K$ 个，真实标签 $y^{(i)}$ 通常是 one-hot 编码向量，$\hat{y}^{(i)}$ 是模型预测每个类别的概率向量，通常是 Softmax 函数的输出)
        *   **分类交叉熵损失 (Categorical Cross-Entropy Loss)**:
            *   **单个样本的损失 (假设 one-hot 编码)**: $L(\hat{y}^{(i)}, y^{(i)}) = - \sum_{k=1}^{K} y_k^{(i)} \log(\hat{y}_k^{(i)})$ (其中 $y_k^{(i)}$ 是真实标签向量的第 $k$ 个元素，$\hat{y}_k^{(i)}$ 是预测概率向量的第 $k$ 个元素)
            *   **整个数据集的代价**: $J(\theta) = - \frac{1}{m} \sum_{i=1}^{m} \sum_{k=1}^{K} y_k^{(i)} \log(\hat{y}_k^{(i)})$
            *   **特点**: 多分类问题中最常用的损失函数，与 Softmax 激活函数配合良好。

---

4.  **选择代价函数 (Choosing a Cost Function):**
    *   代价函数的选择取决于具体的**任务类型**（回归、二分类、多分类等）和模型的**输出层激活函数**。
    *   一个好的代价函数应该能够准确地反映模型的性能，并且其梯度易于计算（或具有良好的数学性质，有助于优化）。

---

**总结 (Summary):**
代价函数是连接模型预测与模型优化的桥梁。它告诉我们模型当前表现如何，并通过其梯度告诉我们应该如何调整参数以改进模型。整个训练过程的核心目标就是找到一组参数 $\theta$ 使得代价函数 $J(\theta)$ 最小化。

### 3. 梯度下降 (Gradient Descent)

![Image/Deep Learning/2.png](/img/user/Image/Deep%20Learning/2.png)
左侧：最优的梯度下降                                    右侧：随机梯度下降（使用Mini-batch减少了计算量）

**引言 (Introduction):**
在前向传播中，我们根据输入和当前的权重、偏置计算出预测结果。但是，我们如何知道当前的权重和偏置是“好”的呢？我们又该如何调整它们使得模型的预测结果更好呢？**梯度下降 (Gradient Descent)** 就是一种常用的优化算法，用于寻找使代价函数 (Cost Function) 最小化的模型参数（如神经网络中的权重 $\omega$ 和偏置 $b$）。它是训练神经网络的核心机制之一。

---

1.  **目标：最小化代价函数 (Objective: Minimize Cost Function)**
    *   **作用**: 衡量模型预测的好坏，并指导模型参数优化的方向。代价函数越小，模型预测越准确。
    *   **代价函数 (Cost Function / 损失函数 Loss Function)**:
        *   在神经网络训练中，我们首先需要一个**代价函数 (Cost Function)** $J(\theta)$ (或称损失函数 Loss Function)。这里的 $\theta$ 代表模型的所有可学习参数（即权重 $\omega$ 和偏置 $b$）。
        *   代价函数用来量化模型的预测值 $(\hat{y})$ 与真实值 $(y)$ 之间的差异。
        *   常见的代价函数有：
            *   **均方误差 (Mean Squared Error, MSE)**: 常用于回归问题。$J(\omega, b) = \frac{1}{2m} \sum_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)})^2$，其中 $m$ 是样本数量。 (这里的 $\frac{1}{2}$ 是为了求导方便)
            *   **交叉熵 (Cross-Entropy)**: 常用于分类问题。
    *   **计算**: 梯度下降算法的目标是迭代地调整参数 $\theta$ (即 $\omega$ 和 $b$)，以找到使代价函数 $J(\theta)$ 达到最小值的参数组合。

---

2.  **核心思想：迭代优化 (Core Idea: Iterative Optimization)**
    *   **作用**: 通过逐步调整参数，使代价函数的值逐渐减小，最终达到或接近最小值。
    *   **直观理解 (Intuition)**:
        *   想象你站在一个连绵起伏的山上（代价函数的图形化表示），你的目标是走到山谷的最低点。
        *   在每一步，你都会观察当前位置哪个方向坡度最陡峭向下，然后朝着那个方向走一小步。
        *   **梯度 (Gradient)**: 在数学上，代价函数 $J(\theta)$ 在某一点的梯度是一个向量，指向该点函数值增长最快的方向。
        *   **下降 (Descent)**: 为了使函数值减小，我们应该沿着梯度的**反方向**更新参数。
    *   **计算**: 这是一个迭代的过程。在每一次迭代中，参数都会向着能使代价函数减小的方向进行微小的调整。

---

3.  **关键步骤与公式 (Key Steps and Formulas)**
    *   **作用**: 具体描述梯度下降是如何通过计算梯度来更新参数的。
    *   **参数**: 我们要优化的参数是神经网络中的权重 $\omega$ 和偏置 $b$。
    *   **计算**:
        1.  **初始化参数**: 随机初始化网络中的所有权重 $\omega$ 和偏置 $b$。
        2.  **计算梯度 (Calculate Gradient)**:
            *   对于当前的参数值，计算代价函数 $J(\omega, b)$ 关于每个参数的偏导数（梯度）。
                *   $\frac{\partial J}{\partial \omega_{jk}^{(l)}}$ : 代价函数对第 $l$ 层，连接第 $k$ 个神经元到第 $l+1$ 层第 $j$ 个神经元的权重的偏导数。
                *   $\frac{\partial J}{\partial b_{j}^{(l)}}$ : 代价函数对第 $l$ 层第 $j$ 个神经元的偏置的偏导数。
            *   这些偏导数指明了如果轻微增加对应参数，代价函数会增加多少。
            *   在神经网络中，这些梯度通常通过**反向传播 (Backpropagation)** 算法来高效计算（反向传播本身是基于链式法则的）。
        3.  **更新参数 (Update Parameters)**:
            *   使用以下规则同时更新所有的权重和偏置：
                $$ \omega_{jk}^{(l)} := \omega_{jk}^{(l)} - \alpha \frac{\partial J}{\partial \omega_{jk}^{(l)}} $$
                $$ b_{j}^{(l)} := b_{j}^{(l)} - \alpha \frac{\partial J}{\partial b_{j}^{(l)}} $$
            *   其中：
                *   `:=` 表示赋值更新。
                *   $\alpha$ (alpha) 是**学习率 (Learning Rate)**，它是一个正的小值（超参数），控制每次参数更新的“步长”。
        4.  **重复**: 重复步骤 2 和 3，直到代价函数 $J(\omega, b)$ 收敛到足够小的值，或者达到预设的最大迭代次数。

---

4.  **学习率 $\alpha$ (Learning Rate)**
    *   **作用**: 控制参数更新的幅度或步长。选择合适的学习率对模型的训练效果和收敛速度至关重要。
    *   **数值选择**: 学习率是一个超参数，需要手动设置或通过实验调整。
    *   **影响**:
        *   **学习率过小**: 收敛速度会非常慢，需要大量的迭代才能达到最优解附近。
        *   **学习率过大**: 更新步长太大，可能会导致参数在最优解附近来回震荡，甚至可能越过最优解导致代价函数发散（不降反升），无法收敛。
        *   **合适的学习率**: 可以保证算法以合理的速度收敛到最优解。

---

5.  **与神经网络训练的联系 (Connection to Neural Network Training)**
    *   **作用**: 将梯度下降置于神经网络训练的完整流程中，解释其在优化网络参数中的核心角色。
    *   **训练流程**:
        1.  **初始化**: 随机初始化网络的权重 $\omega$ 和偏置 $b$。
        2.  **迭代循环 (Epochs)**:
            *   a. **前向传播 (Forward Propagation)**: 将一批训练数据输入网络，从输入层逐层计算到输出层，得到预测值 $\hat{y}$。
            *   b. **计算代价 (Compute Cost)**: 使用代价函数 $J(\omega, b)$ 比较预测值 $\hat{y}$ 和真实标签 $y$，计算当前参数下的代价。
            *   c. **反向传播 (Backward Propagation)**: 从输出层开始，将代价逐层向后传播，计算代价函数 $J$ 关于网络中每一个权重 $\omega$ 和偏置 $b$ 的梯度 ($\frac{\partial J}{\partial \omega}$, $\frac{\partial J}{\partial b}$)。
            *   d. **参数更新 (Update Parameters)**: 使用梯度下降的更新规则和学习率 $\alpha$，根据上一步计算得到的梯度来更新网络中的所有权重 $\omega$ 和偏置 $b$。
        3.  **重复迭代**: 不断重复整个迭代循环（通常是对整个训练数据集进行多轮迭代），直到代价函数收敛或达到预设的训练轮数。**训练的进行就是要通过梯度下降不断改变这些参数($\omega, b$)以达到最优解。**

你提的非常好！Mini-batch 梯度下降是实际训练神经网络时非常关键和常用的技术，我来补充讲解一下，并尽量融入之前的格式。

我们可以在梯度下降部分之后，或者作为一个更具体的梯度下降变体来介绍。这里我将其作为一个新的小节，放在梯度下降之后，反向传播之前或之后都可以，因为它本身是梯度下降的一种实现方式。

考虑到它与实际训练流程紧密相关，放在反向传播之后，作为对整个优化过程的一个更实际的补充，可能更合适。

---

#### 2.1. Mini-batch 梯度下降 (Mini-batch Gradient Descent)

**引言 (Introduction):**
在前面讨论的“基础梯度下降”中，我们提到计算梯度是基于整个训练数据集的（这通常被称为**批量梯度下降 Batch Gradient Descent**）。当训练数据集非常庞大时，每次迭代都对所有数据计算梯度会导致计算成本极高，训练速度缓慢。另一方面，如果我们极端一些，每次只用一个样本来计算梯度并更新参数（这被称为**随机梯度下降 Stochastic Gradient Descent, SGD**），虽然更新快，但梯度估计的方差很大，可能导致收敛过程非常震荡。**Mini-batch 梯度下降 (Mini-batch Gradient Descent)** 是一种非常实用且广泛应用的折衷方案，它试图平衡计算效率和梯度估计的稳定性。

---

1.  **目标：平衡计算效率与更新稳定性 (Objective: Balance Computational Efficiency and Update Stability)**
    *   **作用**: 在可接受的计算时间内，实现相对稳定且快速的参数优化，特别适用于大规模数据集。
    *   **核心**: 每次参数更新时，不是使用全部训练数据，也不是仅使用单个训练样本，而是使用训练数据的一个小子集（这个子集称为一个 "mini-batch"）来估计梯度。
    *   **优势**: 它是目前训练深度神经网络最主流的优化策略之一。

---

2.  **核心思想：分批处理与迭代 (Core Idea: Processing in Batches and Iteration)**
    *   **作用**: 将大规模的训练任务分解为一系列在较小数据批次上的计算，从而提高训练效率并能更好地利用硬件资源。
    *   **Mini-batch 的定义**: 整个训练数据集 $X$ 被划分为若干个不重叠（或有时允许重叠，但通常不重叠）的小数据块，每个数据块称为一个 mini-batch。例如，如果总共有 $m$ 个训练样本，每个 mini-batch 的大小 (batch size) 为 $B$，那么大约会有 $m/B$ 个 mini-batches。
    *   **Epoch 和 Iteration**:
        *   **Iteration (迭代)**: 处理一个 mini-batch 数据并进行一次参数更新的过程称为一次迭代。
        *   **Epoch (轮次)**: 当算法处理完训练数据集中所有的 mini-batches，即对整个训练数据集完整地过了一遍之后，称为完成了一个 epoch。
    *   **计算**:
        *   在一个 epoch 中，算法会依次遍历所有的 mini-batches。
        *   对于每一个 mini-batch，计算该批次数据上的平均梯度（即代价函数对该批次数据的梯度）。
        *   然后使用这个 mini-batch 的梯度来更新模型的权重 $\omega$ 和偏置 $b$。

---

3.  **关键步骤与参数 (Key Steps and Parameters)**
    *   **作用**: 具体描述 Mini-batch 梯度下降的执行流程。
    *   **参数**:
        *   **Batch Size (批大小, $B$)**: 这是最重要的超参数之一，表示每个 mini-batch 中包含的训练样本数量。
            *   常见的 batch size 是 32, 64, 128, 256 等（通常是2的幂次方，以便更好地利用GPU的内存和并行计算能力）。
            *   **选择影响**:
                *   **较小的 Batch Size**: 梯度估计的噪声较大，可能导致收敛曲线震荡，但有时这种噪声有助于模型跳出局部最优点。更新更频繁。
                *   **较大的 Batch Size**: 梯度估计更准确，接近批量梯度下降，收敛更平稳，单次迭代计算量大，但可能更容易陷入尖锐的局部最优点。
    *   **计算流程 (在一个 Epoch 内)**:
        1.  **数据打乱 (Shuffle Data)**: 在每个 epoch 开始之前，通常会对整个训练数据集进行随机打乱。这样做是为了确保每个 mini-batch 的样本是随机抽取的，避免了因数据固定顺序可能带来的偏差，并增加了梯度的随机性，有助于改善训练。
        2.  **划分 Mini-batches**: 将打乱后的训练数据按顺序切分成多个 mini-batches，每个 mini-batch 包含 $B$ 个样本 (最后一个 mini-batch 可能不足 $B$ 个)。
        3.  **遍历 Mini-batches**: 对于第 $t=1, 2, \dots, (\text{num\_mini\_batches})$ 个 mini-batch：
            *   a. **获取当前 Mini-batch 数据**: $X^{\{t\}}, Y^{\{t\}}$。
            *   b. **前向传播 (Forward Propagation)**: 在当前 mini-batch $X^{\{t\}}$ 上进行前向传播，得到预测值 $\hat{Y}^{\{t\}}$。
            *   c. **计算代价 (Compute Cost)**: 计算当前 mini-batch 上的平均代价 $J^{\{t\}}$（即该 mini-batch 中所有样本损失的平均值）。
            *   d. **反向传播 (Backward Propagation)**: 基于当前 mini-batch 的代价 $J^{\{t\}}$，进行反向传播，计算代价函数关于模型参数 $\omega$ 和 $b$ 在这个 mini-batch 上的梯度：$\nabla_{\omega} J^{\{t\}}$ 和 $\nabla_{b} J^{\{t\}}$。
            *   e. **参数更新 (Update Parameters)**: 使用梯度下降规则更新参数：
                $$ \omega := \omega - \alpha \nabla_{\omega} J^{\{t\}} $$
                $$ b := b - \alpha \nabla_{b} J^{\{t\}} $$
                其中 $\alpha$ 是学习率。
        4.  **Epoch 结束**: 当所有 mini-batches 都被处理完毕后，一个 epoch 结束。然后开始下一个 epoch（回到步骤1），重复这个过程，直到满足停止条件（如达到最大 epoch 数或代价函数收敛）。

---

4.  **优点与权衡 (Advantages and Trade-offs)**
    *   **优点**:
        *   **计算效率**: 相比于 Batch GD，每次迭代（处理一个 mini-batch）的计算量大大减少，使得训练过程更快。
        *   **内存效率**: 每次只需要将一个 mini-batch 的数据加载到内存中进行计算。
        *   **更快的收敛**: 参数更新更频繁（每个 mini-batch 更新一次，而不是每个 epoch 才更新一次），通常能比 Batch GD 更快地向最优解收敛。
        *   **利用硬件并行性**: 现代 GPU 等硬件非常适合并行处理大小固定的数据块 (mini-batches)。
        *   **引入噪声，可能跳出局部最优**: Mini-batch 梯度的随机性（因为每个 batch 的数据不同）可以看作是一种噪声，这种噪声有时能帮助算法跳出不好的局部最小值，找到更好的全局解，这类似于 SGD 的特性但更平滑。
    *   **权衡**:
        *   **Batch Size 的选择**: 需要仔细调整 batch size。太小会使训练不稳定，太大则失去了 mini-batch 的一些优势（如快速迭代和噪声带来的好处），并可能增加内存需求。
        *   **梯度不完全准确**: Mini-batch 梯度只是对真实梯度（整个数据集上的梯度）的一个估计，因此收敛路径不会像 Batch GD 那样平滑，会有一些震荡。

---

5.  **在神经网络训练中的核心地位 (Central Role in Neural Network Training)**
    *   **作用**: Mini-batch 梯度下降是训练绝大多数现代深度神经网络的标准方法。
    *   **与之前的流程结合**:
        *   我们之前描述的神经网络训练流程中的“迭代循环”实际上指的就是对 mini-batches 的迭代。
        *   **前向传播、计算代价、反向传播、参数更新**这四个核心步骤都是在当前的 **mini-batch** 上执行的。
        *   一个 **epoch** 包含对所有 mini-batches 的完整遍历。
    *   **进一步优化**: 基于 Mini-batch 梯度下降，还发展出了许多更高级的优化算法，如 Momentum, AdaGrad, RMSProp, Adam 等，它们试图改进学习率的调整或梯度的使用方式，以获得更快的收敛速度和更好的性能，但它们的基础仍然是 Mini-batch 的处理方式。

通过使用 Mini-batch 梯度下降，我们能够在大型数据集上以可接受的计算成本和时间高效地训练复杂的神经网络模型，同时还能从梯度的适度噪声中获益。

### 4. 反向传播 (Backpropagation)

![Image/Deep Learning/3.png](/img/user/Image/Deep%20Learning/3.png)

**引言 (Introduction):**
在梯度下降中，我们需要计算代价函数 $J$ 对于网络中所有权重 $\omega$ 和偏置 $b$ 的偏导数（即梯度 $\frac{\partial J}{\partial \omega}$ 和 $\frac{\partial J}{\partial b}$）。对于只有少量参数的简单模型，我们可以手动推导这些梯度。但是，对于拥有成千上万甚至数百万参数的深度神经网络，手动计算变得不可行。**反向传播 (Backpropagation)** 是一种高效计算这些梯度的算法，它利用了微积分中的**链式法则 (Chain Rule)**，系统地将输出层的误差反向传播到网络中的每一层，从而计算出每个参数对总误差的贡献（即梯度）。

---

1.  **目标：高效计算梯度 (Objective: Efficient Gradient Computation)**
    *   **作用**: 为梯度下降算法提供必需的梯度信息，即 $\frac{\partial J}{\partial \omega_{jk}^{(l)}}$ 和 $\frac{\partial J}{\partial b_{j}^{(l)}}$。
    *   **核心**: 反向传播不是一个优化算法（像梯度下降那样），而是一个用于计算梯度的技术。它的核心任务是计算代价函数相对于网络中每一个可训练参数（权重和偏置）的偏导数。
    *   **重要性**: 没有反向传播，训练深度神经网络几乎是不可能的，因为计算梯度的复杂度会非常高。

---

2.  **核心思想：链式法则与误差反向传播 (Core Idea: Chain Rule and Error Propagation)**
    *   **作用**: 利用链式法则，将输出层的误差逐层向后传递，计算每一层参数对总误差的贡献。
    *   **链式法则 (Chain Rule)**:
        *   神经网络可以看作是一个巨大的复合函数。例如，输出层的激活 $a^{(L)}$ 取决于其加权输入 $z^{(L)}$，而 $z^{(L)}$ 又取决于前一层 $a^{(L-1)}$ 的激活和权重 $W^{(L)}$，以此类推，直到输入层。
        *   如果我们想知道某个深层参数（如 $W^{(1)}$）如何影响最终的代价 $J$，我们需要通过链式法则将 $J$ 对 $a^{(L)}$ 的导数，乘以 $a^{(L)}$ 对 $z^{(L)}$ 的导数，再乘以 $z^{(L)}$ 对 $a^{(L-1)}$ 的导数，等等，一直回溯到 $W^{(1)}$。
        *   例如：若 $J = f(a)$, $a = g(z)$, $z = h(w)x + b$，则 $\frac{\partial J}{\partial w} = \frac{\partial J}{\partial a} \cdot \frac{\partial a}{\partial z} \cdot \frac{\partial z}{\partial w}$。
    *   **误差反向传播 (Error Propagation)**:
        *   反向传播算法从输出层开始计算误差，并将这个误差“信号”向后传播到网络的每一层。
        *   对于每一层，算法会计算该层神经元的“误差项” $\delta^{(l)}$。这个误差项衡量了该层加权输入 $z^{(l)}$ 对最终代价函数的贡献程度。
        *   一旦计算出某层的 $\delta^{(l)}$，就可以很容易地计算出连接到该层的权重和偏置的梯度。

---

3.  **关键步骤与符号 (Key Steps and Notations)**
    *   **作用**: 描述反向传播计算梯度的具体流程。
    *   **前提**:
        *   已经进行了一次**前向传播**，计算并存储了每一层的加权输入 $z^{(l)}$ 和激活值 $a^{(l)}$。
        *   $L$ 是网络的总层数。
        *   $g(z)$ 是激活函数，$g'(z)$ 是其导数。
    *   **计算步骤**:
        1.  **计算输出层误差 ($\delta^{(L)}$)**:
            *   对于输出层 $L$，计算误差项 $\delta^{(L)}$。这通常是代价函数对输出层加权输入 $z^{(L)}$ 的偏导数。
            *   $\delta^{(L)} = \frac{\partial J}{\partial z^{(L)}} = \frac{\partial J}{\partial a^{(L)}} \odot g'(z^{(L)})$
                *   $\frac{\partial J}{\partial a^{(L)}}$ 是代价函数对输出层激活值的导数（例如，对于均方误差和恒等激活函数，这可能是 $(\hat{y} - y)$；对于交叉熵和Sigmoid/Softmax，形式会略有不同但可以直接计算）。
                *   $g'(z^{(L)})$ 是输出层激活函数对其输入的导数。
                *   $\odot$ 表示逐元素乘积 (Hadamard product)。
        2.  **反向传播误差到隐藏层 ($\delta^{(l)}$)**:
            *   对于 $l = L-1, L-2, \dots, 2$ (从倒数第二层逐层向前):
            *   计算第 $l$ 层的误差项 $\delta^{(l)}$，它依赖于下一层（第 $l+1$ 层）的误差项 $\delta^{(l+1)}$ 和连接这两层的权重 $W^{(l+1)}$。
            *   $\delta^{(l)} = ((W^{(l+1)})^T \delta^{(l+1)}) \odot g'(z^{(l)})$
                *   $(W^{(l+1)})^T \delta^{(l+1)}$ 将下一层的误差反向传播到当前层。
                *   $g'(z^{(l)})$ 是当前层激活函数对其输入的导数。
        3.  **计算梯度 ($\frac{\partial J}{\partial W^{(l)}}$ 和 $\frac{\partial J}{\partial b^{(l)}}$)**:
            *   一旦计算出所有层的误差项 $\delta^{(l)}$，就可以计算代价函数 $J$ 对每一层权重 $W^{(l)}$ 和偏置 $b^{(l)}$ 的梯度：
            *   $\frac{\partial J}{\partial W^{(l)}_{jk}} = a_k^{(l-1)} \delta_j^{(l)}$ (即代价函数对连接第 $l-1$ 层第 $k$ 个神经元到第 $l$ 层第 $j$ 个神经元的权重的梯度)
                *   写成矩阵形式：$\frac{\partial J}{\partial W^{(l)}} = \delta^{(l)} (a^{(l-1)})^T$
            *   $\frac{\partial J}{\partial b^{(l)}_{j}} = \delta_j^{(l)}$ (即代价函数对第 $l$ 层第 $j$ 个神经元的偏置的梯度)
                *   写成向量形式：$\frac{\partial J}{\partial b^{(l)}} = \delta^{(l)}$
            *   (注意: 如果是处理一批样本 (mini-batch)，上面的梯度通常是该批次样本梯度的平均值或总和。)

