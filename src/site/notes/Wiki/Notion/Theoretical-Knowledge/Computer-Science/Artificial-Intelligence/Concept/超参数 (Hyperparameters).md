---
{"dg-publish":true,"permalink":"/wiki/notion/theoretical-knowledge/computer-science/artificial-intelligence/concept/hyperparameters/"}
---

在机器学习（包括深度学习）中，模型参数和超参数是两个重要的概念，区分它们对于理解和实践机器学习至关重要。

---

### 什么是超参数 (What are Hyperparameters)?

**超参数是在开始学习过程之前设置值的参数，它们不是通过训练数据直接学习得到的。** 换句话说，超参数是用来**配置学习算法本身**或**定义模型结构**的参数。算法的性能往往对超参数的选择非常敏感。

**与模型参数 (Model Parameters) 的区别:**

*   **模型参数 (Model Parameters)**: 这些是模型在训练过程中从数据中学习到的值。例如：
    *   在线性回归 ($y = wx + b$) 中，$w$ (权重) 和 $b$ (偏置) 是模型参数。
    *   在神经网络中，每一层的权重 ($W$) 和偏置 ($b$) 都是模型参数。
    *   这些参数的值是通过优化算法（如梯度下降）在训练数据上迭代调整以最小化损失函数来确定的。

*   **超参数 (Hyperparameters)**: 这些参数是在训练开始前由用户（或通过自动化超参数优化技术）设定的。例如：
    *   **学习率 ($\eta$ or $\alpha$)**: 在梯度下降中控制参数更新步长。
    *   **迭代次数 (Number of epochs/iterations)**: 训练算法在整个数据集上运行的次数。
    *   **批大小 (Batch size)**: 在 Mini-batch 梯度下降中，每次迭代用于计算梯度的样本数量。
    *   **隐藏层的数量 (Number of hidden layers)**: 在神经网络中。
    *   **每个隐藏层中神经元的数量 (Number of neurons per hidden layer)**: 在神经网络中。
    *   **激活函数的类型 (Type of activation function)**: 如 ReLU, Sigmoid, Tanh。
    *   **正则化参数 (Regularization parameter, e.g., $\lambda$ for L1/L2 regularization)**: 控制正则化强度的系数。
    *   **优化器的类型 (Type of optimizer)**: 如 SGD, Adam, RMSProp。
    *   **K-近邻 (KNN) 算法中的 K 值**。
    *   **支持向量机 (SVM) 中的 C 值和核函数类型 (kernel type)**。
    *   **决策树中的树的最大深度 (max depth)**。

**一个简单的类比:**

*   想象你在烤蛋糕。
    *   **模型参数** 就像蛋糕本身的味道和质地，它们是通过实际的烘烤过程（数据学习）形成的。
    *   **超参数** 就像食谱中的设置，比如烤箱的温度、烘烤的时间、面粉和糖的比例。你需要在开始烤之前就设定好这些，它们会直接影响最终蛋糕（模型）的好坏。

---

### 为什么超参数很重要?

*   **影响模型性能**: 超参数的选择对模型的最终性能（如准确率、泛化能力）有显著影响。不同的超参数组合可能导致模型欠拟合、过拟合或达到理想的性能。
*   **影响训练过程**: 超参数会影响模型的训练速度、收敛性以及所需的计算资源。例如，学习率过大会导致不收敛，学习率过小会导致收敛缓慢。
*   **没有通用的最佳设置**: 对于不同的数据集和不同的问题，最优的超参数组合通常是不同的。没有一组“万能”的超参数。

---

### 如何选择超参数?

选择合适的超参数通常是一个经验性、迭代性的过程，没有固定的公式。常用的方法包括：

1.  **手动调整 (Manual Tuning / Trial and Error)**:
    *   基于经验、直觉或领域知识来手动设置超参数。
    *   运行实验，观察结果（通常在验证集上评估），然后调整超参数，重复此过程。
    *   这是最基本的方法，但可能非常耗时且不一定能找到最优组合。

2.  **网格搜索 (Grid Search)**:
    *   为每个你想要调整的超参数定义一个值的列表（离散的候选值）。
    *   算法会尝试这些列表中所有可能的超参数组合。
    *   例如，如果学习率有 `[0.1, 0.01, 0.001]`，batch size 有 `[32, 64]`，那么网格搜索会尝试 $3 \times 2 = 6$ 种组合。
    *   缺点：当超参数数量较多或每个超参数的候选值较多时，组合数量会呈指数级增长，计算成本非常高。

3.  **随机搜索 (Random Search)**:
    *   与网格搜索类似，也是为每个超参数定义一个值的范围或分布。
    *   但是，随机搜索不是尝试所有组合，而是在定义的空间中随机采样指定数量的超参数组合进行评估。
    *   研究表明，在许多情况下，随机搜索比网格搜索更有效率，因为它不会在不重要的超参数上浪费太多计算资源。

4.  **贝叶斯优化 (Bayesian Optimization)**:
    *   一种更高级的自动化超参数优化技术。
    *   它会构建一个关于超参数与模型性能之间关系的概率模型（代理模型，如高斯过程）。
    *   基于这个模型，它会智能地选择下一个最有希望的超参数组合进行评估，试图在探索（尝试新的、不确定的区域）和利用（在已知表现好的区域附近尝试）之间取得平衡。
    *   通常比网格搜索和随机搜索需要更少的评估次数就能找到较好的超参数。

5.  **基于梯度的优化 (Gradient-based Optimization)**:
    *   对于某些特定的超参数（如果可以对其求导），可以尝试使用基于梯度的方法进行优化。但这在实践中较少见，因为大多数超参数是离散的或难以直接求导。

6.  **进化算法 (Evolutionary Algorithms)**:
    *   模拟生物进化过程，如遗传算法，来搜索最优的超参数组合。

**评估超参数组合**:
无论使用哪种搜索方法，评估一个超参数组合的好坏通常是在**验证集 (Validation Set)** 上进行的，而不是在训练集或测试集上。
*   **训练集 (Training Set)**: 用于学习模型参数。
*   **验证集 (Validation Set)**: 用于选择超参数和评估不同模型配置。
*   **测试集 (Test Set)**: 在最终选定模型和超参数后，用于评估模型的最终泛化能力，它应该只在最后使用一次。

---

*   **超参数**是在训练开始前设置的，用于配置学习算法或模型结构的参数。
*   它们与模型在训练中学习到的**模型参数**不同。
*   超参数的选择对模型性能和训练过程至关重要。
*   选择超参数是一个迭代的过程，常用的方法包括手动调整、网格搜索、随机搜索和贝叶斯优化等自动化技术。
*   超参数的评估通常在验证集上进行。
